{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616faa23-2d03-4472-a27e-f964a1719883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4313bc2-63fc-4e73-b404-b3ddfcf67bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_dim=28*28):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=28*28):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de8e5a1-7256-4288-97dc-7c182a35baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 9912422/9912422 [00:01<00:00, 5598890.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 28881/28881 [00:00<00:00, 195179.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1648877/1648877 [00:00<00:00, 1657546.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 4542/4542 [00:00<00:00, 8058599.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Splitting dataset into labeled and unlabeled sets\n",
    "labeled_size = 1000\n",
    "unlabeled_size = len(dataset) - labeled_size\n",
    "labeled_data, unlabeled_data = random_split(dataset, [labeled_size, unlabeled_size])\n",
    "\n",
    "labeled_loader = DataLoader(labeled_data, batch_size=64, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890b5c4c-8092-451c-84fb-61136869b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Loss D: 0.4546, loss G: 0.5527\n",
      "Epoch [2/50] Loss D: 0.3674, loss G: 0.7756\n",
      "Epoch [3/50] Loss D: 0.4877, loss G: 0.6377\n",
      "Epoch [4/50] Loss D: 0.4712, loss G: 0.7457\n",
      "Epoch [5/50] Loss D: 0.3801, loss G: 0.9248\n",
      "Epoch [6/50] Loss D: 0.4446, loss G: 0.8223\n",
      "Epoch [7/50] Loss D: 0.4110, loss G: 0.9564\n",
      "Epoch [8/50] Loss D: 0.2840, loss G: 1.3797\n",
      "Epoch [9/50] Loss D: 0.1410, loss G: 1.9801\n",
      "Epoch [10/50] Loss D: 0.1162, loss G: 2.1833\n",
      "Epoch [11/50] Loss D: 0.1425, loss G: 1.9609\n",
      "Epoch [12/50] Loss D: 0.1751, loss G: 1.8019\n",
      "Epoch [13/50] Loss D: 0.1314, loss G: 2.0619\n",
      "Epoch [14/50] Loss D: 0.1118, loss G: 2.1460\n",
      "Epoch [15/50] Loss D: 0.1652, loss G: 1.7613\n",
      "Epoch [16/50] Loss D: 0.2731, loss G: 1.2973\n",
      "Epoch [17/50] Loss D: 0.4354, loss G: 0.9109\n",
      "Epoch [18/50] Loss D: 0.2954, loss G: 1.2474\n",
      "Epoch [19/50] Loss D: 0.5912, loss G: 0.7116\n",
      "Epoch [20/50] Loss D: 0.6709, loss G: 0.6034\n",
      "Epoch [21/50] Loss D: 0.5172, loss G: 0.7640\n",
      "Epoch [22/50] Loss D: 0.3585, loss G: 1.1538\n",
      "Epoch [23/50] Loss D: 0.4607, loss G: 0.9689\n",
      "Epoch [24/50] Loss D: 0.6222, loss G: 0.6795\n",
      "Epoch [25/50] Loss D: 0.6802, loss G: 0.6277\n",
      "Epoch [26/50] Loss D: 0.4069, loss G: 1.1194\n",
      "Epoch [27/50] Loss D: 0.2229, loss G: 1.7086\n",
      "Epoch [28/50] Loss D: 0.3324, loss G: 1.3979\n",
      "Epoch [29/50] Loss D: 0.3213, loss G: 1.5882\n",
      "Epoch [30/50] Loss D: 0.2689, loss G: 1.7355\n",
      "Epoch [31/50] Loss D: 0.1396, loss G: 2.1261\n",
      "Epoch [32/50] Loss D: 0.1842, loss G: 1.9262\n",
      "Epoch [33/50] Loss D: 0.3270, loss G: 1.2487\n",
      "Epoch [34/50] Loss D: 0.4053, loss G: 1.1302\n",
      "Epoch [35/50] Loss D: 0.3687, loss G: 1.2517\n",
      "Epoch [36/50] Loss D: 0.3194, loss G: 1.4093\n",
      "Epoch [37/50] Loss D: 0.3466, loss G: 1.3121\n",
      "Epoch [38/50] Loss D: 0.3422, loss G: 1.3417\n",
      "Epoch [39/50] Loss D: 0.3320, loss G: 1.4383\n",
      "Epoch [40/50] Loss D: 0.4972, loss G: 1.0464\n",
      "Epoch [41/50] Loss D: 0.4207, loss G: 1.2392\n",
      "Epoch [42/50] Loss D: 0.3426, loss G: 1.4567\n",
      "Epoch [43/50] Loss D: 0.3007, loss G: 1.5513\n",
      "Epoch [44/50] Loss D: 0.3082, loss G: 1.4145\n",
      "Epoch [45/50] Loss D: 0.3167, loss G: 1.5720\n",
      "Epoch [46/50] Loss D: 0.3105, loss G: 1.5825\n",
      "Epoch [47/50] Loss D: 0.2956, loss G: 1.4904\n",
      "Epoch [48/50] Loss D: 0.2125, loss G: 1.8990\n",
      "Epoch [49/50] Loss D: 0.1248, loss G: 2.1929\n",
      "Epoch [50/50] Loss D: 0.1815, loss G: 1.8862\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "z_dim = 100\n",
    "img_dim = 28*28\n",
    "lr = 0.0002\n",
    "num_epochs = 50\n",
    "\n",
    "gen = Generator(z_dim).to(device)\n",
    "disc = Discriminator(img_dim).to(device)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for (real, _), _ in zip(labeled_loader, unlabeled_loader):\n",
    "        real = real.view(-1, 28*28).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        # Train Discriminator\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake).view(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\")\n",
    "\n",
    "# Save the trained models\n",
    "torch.save(gen.state_dict(), \"generator.pth\")\n",
    "torch.save(disc.state_dict(), \"discriminator.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8544cd-3d10-495c-927f-3b4b4782a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Loss: 1.9339\n",
      "Epoch [2/50] Loss: 1.4965\n",
      "Epoch [3/50] Loss: 1.1181\n",
      "Epoch [4/50] Loss: 1.0773\n",
      "Epoch [5/50] Loss: 0.8905\n",
      "Epoch [6/50] Loss: 0.7065\n",
      "Epoch [7/50] Loss: 0.7730\n",
      "Epoch [8/50] Loss: 0.5604\n",
      "Epoch [9/50] Loss: 0.7145\n",
      "Epoch [10/50] Loss: 0.6730\n",
      "Epoch [11/50] Loss: 0.3918\n",
      "Epoch [12/50] Loss: 0.5106\n",
      "Epoch [13/50] Loss: 0.4982\n",
      "Epoch [14/50] Loss: 0.5505\n",
      "Epoch [15/50] Loss: 0.4640\n",
      "Epoch [16/50] Loss: 0.2667\n",
      "Epoch [17/50] Loss: 0.5339\n",
      "Epoch [18/50] Loss: 0.2827\n",
      "Epoch [19/50] Loss: 0.3184\n",
      "Epoch [20/50] Loss: 0.4288\n",
      "Epoch [21/50] Loss: 0.2706\n",
      "Epoch [22/50] Loss: 0.2987\n",
      "Epoch [23/50] Loss: 0.2334\n",
      "Epoch [24/50] Loss: 0.2488\n",
      "Epoch [25/50] Loss: 0.1967\n",
      "Epoch [26/50] Loss: 0.5042\n",
      "Epoch [27/50] Loss: 0.3402\n",
      "Epoch [28/50] Loss: 0.2527\n",
      "Epoch [29/50] Loss: 0.3566\n",
      "Epoch [30/50] Loss: 0.2852\n",
      "Epoch [31/50] Loss: 0.1853\n",
      "Epoch [32/50] Loss: 0.2440\n",
      "Epoch [33/50] Loss: 0.2029\n",
      "Epoch [34/50] Loss: 0.2275\n",
      "Epoch [35/50] Loss: 0.3487\n",
      "Epoch [36/50] Loss: 0.2356\n",
      "Epoch [37/50] Loss: 0.1936\n",
      "Epoch [38/50] Loss: 0.2534\n",
      "Epoch [39/50] Loss: 0.3096\n",
      "Epoch [40/50] Loss: 0.2634\n",
      "Epoch [41/50] Loss: 0.1976\n",
      "Epoch [42/50] Loss: 0.2124\n",
      "Epoch [43/50] Loss: 0.1794\n",
      "Epoch [44/50] Loss: 0.2584\n",
      "Epoch [45/50] Loss: 0.1697\n",
      "Epoch [46/50] Loss: 0.1712\n",
      "Epoch [47/50] Loss: 0.1398\n",
      "Epoch [48/50] Loss: 0.1137\n",
      "Epoch [49/50] Loss: 0.1665\n",
      "Epoch [50/50] Loss: 0.1167\n",
      "Accuracy: 88.12%\n"
     ]
    }
   ],
   "source": [
    "class DiscriminatorWithClassifier(nn.Module):\n",
    "    def __init__(self, img_dim=28*28, num_classes=10):\n",
    "        super(DiscriminatorWithClassifier, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.disc(x)\n",
    "        class_logits = self.classifier(features)\n",
    "        return class_logits\n",
    "\n",
    "classifier = DiscriminatorWithClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=lr)\n",
    "\n",
    "# Train the classifier\n",
    "for epoch in range(num_epochs):\n",
    "    for real, labels in labeled_loader:\n",
    "        real = real.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = classifier(real)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluate the classifier\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "classifier.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for real, labels in test_loader:\n",
    "        real = real.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = classifier(real)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcfc970-818a-4e03-91ad-b80c069f2230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
